# Readme

---

## sparse data

---

### 데이터 분석

1. 데이터 이상치 확인 ( Null 값 확인 )

2. 데이터분석
    - 4,5번 칼럼
        - 5의 시간이 항상 4보다 빠름
        - 두 값은 무언가 진행되는 시간의 경과라고 생각 함
        - 따라서 두 값의 차이의 day만을 사용하여 학습 데이터로 사용함.
    
    - 1번 칼럼
        - 행마다 길이, 수 다 다름
        - 패턴을 찾기 힘들다고 생각함
        - 0 0 0 4 0 0 이런 식의 데이터를 학습시키기위해 데이터의 정보를 칼럼에 다시 저장함

#### 1번 칼럼의 데이터를 loc, data 칼럼으로 변환
1. 0 0 0 4 0 --> 4의 **위치정보**를 loc에 3으로
    loc 3의 **값**을 data 에 4로 저장
2. -1로 패딩하여 길이를 맞춰줌
3. 이 값을 xgboost에 학습 시키기 위해 리스트를 풀어서 dataframe 칼럼으로 변경
4. column명 중복을 없애기 위해 칼럼명을 수정함
5. xgboost 모델을 불러와 학습 진행
    - model.sparse.dat 파일로 학습된 모델 저장
    train과 test의 비율을 8:2로 진행하였고 test accuracy는
    0.8932%로 나왔다.

* 저장된 모델로 test.sparse.tsv 학습에 문제 있음
    - 학습 칼럼 수와 테스트 칼럼 수가 달라서 학습이 안됨
    - 앞에서 패딩해준것과 동일하게 train칼럼수에 맞게 test 칼럼 수를 추가해주고 값은 -1로 패딩하고 predict 진행
    - 추후에 실제로 온라인 상에서 데이터를 받아 학습을 추가하고 예측을 하는 단계에서는 패딩 방식 외에 학습망 변경, 칼럼 데이터 수정 등을 논의해야 할 필요가 있음
    - 기존에 training시에 패딩으로 학습시켰을때 test결과가 괜찮았기에 우선은 패딩방식 적용

___

## dense data

___

- sparse data에서 사용한 xgboost 모델을 적용하였다.
- dense data는 다른 데이터 전처리 없이 그대로 라벨과 training data를 분리하여 학습을 진행

- train, test 8:2로 진행하였고
- test accuracy는 0.97945%가 나옴

- 학습망의 재사용과, 좋은 정확도로 인해 추가적인 작업 없이 모델 사용
- test.dense.tsv파일도 train 데이터와 마찬가지로 별도의 전처리 과정없이 모델을 load해오고
predict를 진행하였다.
- 예측 라벨은 txt파일에 한 줄 씩 저장하였다.


```python

```
