# Readme

---

## sparse data

------

### 데이터 분석

import pandas as pd

original_data = pd.read_csv('./data/train.sparse.tsv', delimiter="\t", header=None)


```python
original_data.head()
```

1. 데이터 이상치 확인 ( Null 값 확인 )

2. 데이터분석

    - 4,5번 칼럼
        - 5의 시간이 항상 4보다 빠름
        - 두 값은 무언가 진행되는 시간의 경과라고 생각 함
        - 따라서 두 값의 차이의 day만을 사용하여 학습 데이터로 사용함
    
    - 1번 칼럼
        - 행마다 길이, 수 다 다름
        - 패턴을 찾기 힘들다고 생각함
        - 0 0 0 4 0 0 의 데이터를 학습시키기위해 데이터의 정보를 칼럼에 다시 저장함
    

#### 1번 칼럼의 데이터를 loc, data 칼럼으로 변환
1. 0 0 0 4 0 --> 4의 **위치정보**를 loc에 3으로
    loc 3의 **값**을 data 에 4로 저장


```python
te_df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>loc</th>
      <th>data</th>
      <th>etc1</th>
      <th>etc2</th>
      <th>a_date</th>
      <th>c_date</th>
      <th>etc3</th>
      <th>etc4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[6, 7, 8, 9, 10, 13, 15, 23, 33, -1, -1, -1, -...</td>
      <td>[115, 116, 1048, 3741, 87, 121, 6194, 23, 23, ...</td>
      <td>1</td>
      <td>1</td>
      <td>2021-03-15 06:39:47</td>
      <td>2021-06-07 14:03:58</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[2, 11, 15, 17, 26, 28, 31, 36, 38, 40, -1, -1...</td>
      <td>[41619, 881, 304, 1082, 516, 27, 1020, 17092, ...</td>
      <td>18</td>
      <td>1</td>
      <td>2018-10-25 11:52:02</td>
      <td>2019-12-09 06:41:29</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>
      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>
      <td>19</td>
      <td>2</td>
      <td>2021-05-12 06:05:09</td>
      <td>2021-05-13 05:11:09</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[1, 6, 8, 10, 12, 18, 19, 22, 23, 32, 36, -1, ...</td>
      <td>[4, 316, 25, 265, 13372, 330, 183, 570, 400, 2...</td>
      <td>1</td>
      <td>1</td>
      <td>2019-08-27 01:41:07</td>
      <td>2019-10-03 08:17:08</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[2, 3, 10, 13, 16, 28, 33, 34, -1, -1, -1, -1,...</td>
      <td>[225, 1223, 1228, 5260, 3202, 255, 15238, 37, ...</td>
      <td>1</td>
      <td>1</td>
      <td>2020-06-09 07:04:31</td>
      <td>2020-06-11 15:34:18</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>99995</th>
      <td>[6, 8, 15, 16, 27, 32, -1, -1, -1, -1, -1, -1,...</td>
      <td>[115, 2162, 27, 15976, 705, 27, -1, -1, -1, -1...</td>
      <td>1</td>
      <td>1</td>
      <td>2020-05-20 06:54:51</td>
      <td>2020-07-29 02:54:39</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>99996</th>
      <td>[1, 6, 12, 14, 20, 28, 30, 34, -1, -1, -1, -1,...</td>
      <td>[4, 115, 16036, 255, 181, 37, 27, 23, -1, -1, ...</td>
      <td>1</td>
      <td>1</td>
      <td>2020-05-20 06:54:51</td>
      <td>2020-07-29 02:54:40</td>
      <td>3</td>
      <td>2</td>
    </tr>
    <tr>
      <th>99997</th>
      <td>[0, 2, 4, 6, 9, 18, 21, 28, 29, 31, 35, 42, 43...</td>
      <td>[3, 1238, 15524, 8773, 9836, 15527, 888, 9744,...</td>
      <td>1</td>
      <td>1</td>
      <td>2020-07-03 02:31:16</td>
      <td>2020-08-06 05:55:00</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>99998</th>
      <td>[2, 11, 14, 16, 20, 27, 30, 32, 36, -1, -1, -1...</td>
      <td>[947, 32351, 5712, 37, 2025, 1038, 3852, 23, 1...</td>
      <td>1</td>
      <td>1</td>
      <td>2020-10-29 05:52:35</td>
      <td>2020-12-17 07:30:39</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>99999</th>
      <td>[19, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>
      <td>[96, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>
      <td>7</td>
      <td>1</td>
      <td>2020-04-07 06:00:49</td>
      <td>2020-12-17 09:10:20</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>100000 rows × 8 columns</p>
</div>



2. -1로 패딩하여 길이를 맞춰줌
3. 이 값을 xgboost에 학습 시키기 위해 리스트를 풀어서 dataframe 칼럼으로 변경
4. column명 중복을 없애기 위해 칼럼명을 수정함
5. xgboost 모델을 불러와 학습 진행
    - model.sparse.dat 파일로 학습된 모델 저장
    train과 test의 비율을 8:2로 진행하였고 test accuracy는
    **0.8932*%로 나왔다.

* 저장된 모델로 test.sparse.tsv 학습에 문제 있음
    - 학습 칼럼 수와 테스트 칼럼 수가 달라서 학습이 안됨
    - 앞에서 패딩해준것과 동일하게 train칼럼수에 맞게 test 칼럼 수를 추가해주고 값은 -1로 패딩하고 predict 진행
    - 추후에 실제로 온라인 상에서 데이터를 받아 학습을 추가하고 예측을 하는 단계에서는 패딩 방식 외에 학습망 변경, 칼럼 데이터 수정 등을 논의해야 할 필요가 있음
    - 기존에 training시에 패딩으로 학습시켰을때 test결과가 괜찮았기에 우선은 패딩방식 적용

___

## dense data

___

- sparse data에서 사용한 xgboost 모델을 적용하였다.
- dense data는 다른 데이터 전처리 없이 그대로 라벨과 training data를 분리하여 학습을 진행

- train, test 8:2로 진행하였고
- test accuracy는
- *0.97945*%가 나옴


```python
- 학습망의 재사용과, 좋은 정확도로 인해 추가적인 작업 없이 모델 사용
- test.dense.tsv파일도 train 데이터와 마찬가지로 별도의 전처리 과정없이
학
```


```python

```
